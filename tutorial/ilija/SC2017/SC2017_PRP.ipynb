{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling SC2017 PRP productions\n",
    "\n",
    "This module has functions to:\n",
    "- create all the workload\n",
    "- move from state to state [created,training,trained,generating,generated,transporting,done]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "from time import time, sleep\n",
    "from elasticsearch import Elasticsearch, exceptions as es_exceptions\n",
    "es = Elasticsearch(['atlas-kibana.mwt2.org:9200'],timeout=60)\n",
    "index_name='sc2017'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"acknowledged\":true}"
     ]
    }
   ],
   "source": [
    "! curl -XPOST \"atlas-kibana.mwt2.org:9200/_template/sc2017\" -d @SC2017_template.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " [--nb-epochs NB_EPOCHS] \n",
    " [--batch-size BATCH_SIZE]\n",
    " [--latent-size LATENT_SIZE] \n",
    " [--disc-lr DISC_LR]\n",
    " [--gen-lr GEN_LR] \n",
    " [--adam-beta ADAM_BETA] \n",
    " [--prog-bar]\n",
    " [--no-attn] \n",
    " [--debug] \n",
    " [--d-pfx D_PFX] \n",
    " [--g-pfx G_PFX]\n",
    " dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_workload():\n",
    "    \n",
    "    # clean all\n",
    "    try:\n",
    "        es.indices.delete(index='sc2017')\n",
    "    except:\n",
    "        print(\"not there?\")\n",
    "    \n",
    "    id=0\n",
    "    \n",
    "    l0 = ['--nb-epochs=50','--nb-epochs=100','--nb-epochs=200',]\n",
    "    l1 = ['--disc-lr=0.0001','--disc-lr=0.0002','--disc-lr=0.0005']\n",
    "    l2  = ['--gen-lr=0.00001','--gen-lr=0.00002','--gen-lr=0.00005']\n",
    "    l3    = ['', '--no-attn']\n",
    "    l4    = ['gamma.yaml', 'eplus.yaml', 'pion.yaml']\n",
    "    for a in l0:\n",
    "        for b in l1:\n",
    "            for c in l2:\n",
    "                for d in l3:\n",
    "                    for e in l4:\n",
    "                        doc={}\n",
    "                        doc['created']=int(time()*1000)\n",
    "                        doc['status']='created'\n",
    "                        doc['training_options']=['--output_folder=/data/CaloGAN/weights/'+str(id)]\n",
    "                        if d!='': doc['training_options'].append(d)\n",
    "                        doc['training_options']+=[a, b, c, e]\n",
    "                        doc['generating_options']=[\n",
    "                                                   '--input_folder=/data/CaloGAN/weights/'+str(id), \n",
    "                                                   '--output_folder=/data/CaloGAN/outputs/'+str(id), \n",
    "                                                   '--sets=10', \n",
    "                                                   '--showers=100000'\n",
    "                                                  ]\n",
    "                        id+=1\n",
    "#                         print(doc)\n",
    "                        es.create(index=index_name, doc_type='doc', id=id, body=doc)\n",
    "\n",
    "def get_training_job():\n",
    "    my_query={\n",
    "        \"size\": 1,\n",
    "        \"query\":{ \n",
    "            \"term\": {\"status\":\"created\"} \n",
    "        }\n",
    "    }\n",
    "\n",
    "    res = es.search(index=index_name, body=my_query )\n",
    "    res=res['hits']\n",
    "    if res['total']==0:\n",
    "        print('no training jobs at the moment.')\n",
    "        return\n",
    "    res_id=res['hits'][0]['_id']\n",
    "    res=res['hits'][0]['_source']\n",
    "    \n",
    "    res['status']='training'\n",
    "    res['start_training']=int(time()*1000)\n",
    "    es.update(index=index_name, doc_type='doc', id=res_id, body={\"doc\":res})\n",
    "    return (res_id, res)\n",
    "\n",
    "def get_generating_job():\n",
    "    my_query={\n",
    "        \"size\": 1,\n",
    "        \"query\":{ \n",
    "            \"term\": {\"status\":\"trained\"} \n",
    "        }\n",
    "    }\n",
    "\n",
    "    res = es.search(index=index_name, body=my_query )\n",
    "    res=res['hits']\n",
    "    if res['total']==0:\n",
    "        print('no generating jobs at the moment.')\n",
    "        return\n",
    "    res_id=res['hits'][0]['_id']\n",
    "    res=res['hits'][0]['_source']\n",
    "    \n",
    "    res['status']='generating'\n",
    "    res['start_generating']=int(time()*1000)\n",
    "    es.update(index=index_name, doc_type='doc', id=res_id, body={\"doc\":res})\n",
    "    return (res_id, res)\n",
    "\n",
    "def get_transfering_job():\n",
    "    my_query={\n",
    "        \"size\": 1,\n",
    "        \"query\":{ \n",
    "            \"term\": {\"status\":\"generated\"} \n",
    "        }\n",
    "    }\n",
    "\n",
    "    res = es.search(index=index_name, body=my_query )\n",
    "    res=res['hits']\n",
    "    if res['total']==0:\n",
    "        print('no transfering jobs at the moment.')\n",
    "        return\n",
    "    res_id=res['hits'][0]['_id']\n",
    "    res=res['hits'][0]['_source']\n",
    "    \n",
    "    res['status']='transfering'\n",
    "    res['start_transfering']=int(time()*1000)\n",
    "    es.update(index=index_name, doc_type='doc', id=res_id, body={\"doc\":res})\n",
    "    return (res_id, res)\n",
    "\n",
    "def done_training(id):\n",
    "    res={'status':'trained', 'end_training':int(time()*1000) }\n",
    "    es.update(index=index_name, doc_type='doc', id=id, body={\"doc\":res})\n",
    "\n",
    "def done_generating(id):\n",
    "    res={'status':'generated', 'end_generating':int(time()*1000) }\n",
    "    es.update(index=index_name, doc_type='doc', id=id, body={\"doc\":res})\n",
    "\n",
    "def done_transfering(id):\n",
    "    res={'status':'transfered', 'end_transfering':int(time()*1000) }\n",
    "    es.update(index=index_name, doc_type='doc', id=id, body={\"doc\":res})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test all the steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'created', 'created': 1509839604511, 'generating_options': ['--input_folder=/data/CaloGAN/weigths/129', '--output_folder=/data/CaloGAN/outputs/129', '--sets=10', '--showers=100000'], 'training_options': ['--output_folder=/data/CaloGAN/weigths/129', '--nb-epochs=200', '--disc-lr=0.0002', '--gen-lr=0.00001', '--no-attn', 'gamma.yaml']}\n",
      "130 {'status': 'training', 'start_training': 1509839606751, 'created': 1509839604511, 'generating_options': ['--input_folder=/data/CaloGAN/weigths/129', '--output_folder=/data/CaloGAN/outputs/129', '--sets=10', '--showers=100000'], 'training_options': ['--output_folder=/data/CaloGAN/weigths/129', '--nb-epochs=200', '--disc-lr=0.0002', '--gen-lr=0.00001', '--no-attn', 'gamma.yaml']}\n",
      "{'end_training': 1509839611821, 'training_options': ['--output_folder=/data/CaloGAN/weigths/129', '--nb-epochs=200', '--disc-lr=0.0002', '--gen-lr=0.00001', '--no-attn', 'gamma.yaml'], 'generating_options': ['--input_folder=/data/CaloGAN/weigths/129', '--output_folder=/data/CaloGAN/outputs/129', '--sets=10', '--showers=100000'], 'start_training': 1509839606751, 'status': 'trained', 'created': 1509839604511}\n",
      "130 {'end_training': 1509839611821, 'training_options': ['--output_folder=/data/CaloGAN/weigths/129', '--nb-epochs=200', '--disc-lr=0.0002', '--gen-lr=0.00001', '--no-attn', 'gamma.yaml'], 'generating_options': ['--input_folder=/data/CaloGAN/weigths/129', '--output_folder=/data/CaloGAN/outputs/129', '--sets=10', '--showers=100000'], 'start_generating': 1509839626960, 'start_training': 1509839606751, 'status': 'generating', 'created': 1509839604511}\n",
      "{'end_training': 1509839611821, 'training_options': ['--output_folder=/data/CaloGAN/weigths/129', '--nb-epochs=200', '--disc-lr=0.0002', '--gen-lr=0.00001', '--no-attn', 'gamma.yaml'], 'generating_options': ['--input_folder=/data/CaloGAN/weigths/129', '--output_folder=/data/CaloGAN/outputs/129', '--sets=10', '--showers=100000'], 'start_generating': 1509839626960, 'start_training': 1509839606751, 'end_generating': 1509839632029, 'status': 'generated', 'created': 1509839604511}\n",
      "130 {'start_transfering': 1509839647183, 'end_training': 1509839611821, 'training_options': ['--output_folder=/data/CaloGAN/weigths/129', '--nb-epochs=200', '--disc-lr=0.0002', '--gen-lr=0.00001', '--no-attn', 'gamma.yaml'], 'generating_options': ['--input_folder=/data/CaloGAN/weigths/129', '--output_folder=/data/CaloGAN/outputs/129', '--sets=10', '--showers=100000'], 'start_generating': 1509839626960, 'start_training': 1509839606751, 'end_generating': 1509839632029, 'status': 'transfering', 'created': 1509839604511}\n"
     ]
    }
   ],
   "source": [
    "def test_flow():\n",
    "    \n",
    "    create_workload()\n",
    "\n",
    "    (id, job) = get_training_job()\n",
    "    print(id, job)\n",
    "    sleep(5)\n",
    "    done_training(id)\n",
    "\n",
    "    sleep(15)\n",
    "\n",
    "    (id, job) = get_generating_job()\n",
    "    print(id, job)\n",
    "    sleep(5)\n",
    "    done_generating(id)\n",
    "\n",
    "    sleep(15)\n",
    "\n",
    "    (id, job) = get_transfering_job()\n",
    "    print(id, job)\n",
    "    sleep(5)\n",
    "    done_transfering(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    if len(argv)!=2:\n",
    "        print('Usage - sc2017.py <creator|trainer|generator|transporter>')\n",
    "    else:\n",
    "        print( 'this pod will be:', argv[1] )\n",
    "    \n",
    "    role=argv[1]\n",
    "    if role=='creator':\n",
    "        create_workload()\n",
    "    elif role=='trainer':\n",
    "        while (True):\n",
    "            (id, job) = get_training_job()\n",
    "            print('training job:',id, '\\nsetting up:\\n', job)\n",
    "            output = subprocess.check_output(['train.py']+job['training_options'])\n",
    "            print(output)\n",
    "            done_training(id)\n",
    "            sleep(15)\n",
    "    elif role=='generator':\n",
    "        while (True):\n",
    "            (id, job) = get_generating_job()\n",
    "            print('generator job:',id, '\\nsetting up:\\n', job)\n",
    "            output = subprocess.check_output(['generator.py']+job['generating_options'])\n",
    "            print(output)\n",
    "            done_generating(id)\n",
    "            sleep(15)\n",
    "    elif role=='transporter':\n",
    "        while (True):\n",
    "            (id, job) = get_transfering_job()\n",
    "            print('transporter job:',id, '\\nsetting up:\\n', job)\n",
    "            output = subprocess.check_output(['xrdcp ']+job['transfering_options'])\n",
    "            print(output)\n",
    "            done_transfering(id)\n",
    "            sleep(15)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_workload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
