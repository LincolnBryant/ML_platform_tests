{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling SC2017 PRP productions\n",
    "\n",
    "This module has functions to:\n",
    "- create all the workload\n",
    "- move from state to state [created,training,trained,generating,generated,transporting,done]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from elasticsearch import Elasticsearch, exceptions as es_exceptions\n",
    "es = Elasticsearch(['atlas-kibana.mwt2.org:9200'],timeout=60)\n",
    "index_name='sc2017'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl -XPOST \"atlas-kibana.mwt2.org:9200/_template/sc2017\" -d @SC2017_template.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " [--nb-epochs NB_EPOCHS] \n",
    " [--batch-size BATCH_SIZE]\n",
    " [--latent-size LATENT_SIZE] \n",
    " [--disc-lr DISC_LR]\n",
    " [--gen-lr GEN_LR] \n",
    " [--adam-beta ADAM_BETA] \n",
    " [--prog-bar]\n",
    " [--no-attn] \n",
    " [--debug] \n",
    " [--d-pfx D_PFX] \n",
    " [--g-pfx G_PFX]\n",
    " dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_workload():\n",
    "    \n",
    "    # clean all\n",
    "    try:\n",
    "        es.indices.delete(index='sc2017')\n",
    "    except:\n",
    "        print(\"not there?\")\n",
    "    \n",
    "    id=0\n",
    "    \n",
    "    l0 = ['--nb-epochs=50','--nb-epochs=100','--nb-epochs=200',]\n",
    "    l1 = ['--disc-lr=0.0001','--disc-lr=0.0002','--disc-lr=0.0005']\n",
    "    l2  = ['--gen-lr=0.00001','--gen-lr=0.00002','--gen-lr=0.00005']\n",
    "    l3    = ['', '--no-attn']\n",
    "    l4    = ['gamma.yaml', 'eplus.yaml', 'pion.yaml']\n",
    "    for a in l0:\n",
    "        for b in l1:\n",
    "            for c in l2:\n",
    "                for d in l3:\n",
    "                    for e in l4:\n",
    "                        doc={}\n",
    "                        doc['created']=int(time()*1000)\n",
    "                        doc['status']='created'\n",
    "                        doc['training_options']=['--output_folder=/data/CaloGAN/weigths/'+str(id), a, b, c, d, e]\n",
    "                        doc['generating_options']=[\n",
    "                                                   '--input_folder=/data/CaloGAN/weigths/'+str(id), \n",
    "                                                   '--output_folder=/data/CaloGAN/outputs/'+str(id), \n",
    "                                                   '--sets=10', \n",
    "                                                   '--showers=100000'\n",
    "                                                  ]\n",
    "                        id+=1\n",
    "#                         print(doc)\n",
    "                        es.create(index=index_name, doc_type='doc', id=id, body=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_job():\n",
    "    my_query={\n",
    "        \"size\": 1,\n",
    "        \"query\":{ \n",
    "            \"term\": {\"status\":\"created\"} \n",
    "        }\n",
    "    }\n",
    "\n",
    "    res = es.search(index=index_name, body=my_query )\n",
    "    res=res['hits']\n",
    "    if res['total']==0:\n",
    "        print('no training jobs at the moment.')\n",
    "        return\n",
    "    res_id=res['hits'][0]['_id']\n",
    "    res=res['hits'][0]['_source']\n",
    "    print(res)\n",
    "        \n",
    "    #now update to training...\n",
    "    \n",
    "    res['status']='training'\n",
    "    res['start_training']=int(time()*1000)\n",
    "    es.update(index=index_name, doc_type='doc', id=res_id, body={\"doc\":res})\n",
    "    return (res_id, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def done_training(id):\n",
    "    res={'status':'trained', 'end_training':int(time()*1000) }\n",
    "    es.update(index=index_name, doc_type='doc', id=id, body={\"doc\":res})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generating_job():\n",
    "    my_query={\n",
    "        \"size\": 1,\n",
    "        \"query\":{ \n",
    "            \"term\": {\"status\":\"trained\"} \n",
    "        }\n",
    "    }\n",
    "\n",
    "    res = es.search(index=index_name, body=my_query )\n",
    "    res=res['hits']\n",
    "    if res['total']==0:\n",
    "        print('no generating jobs at the moment.')\n",
    "        return\n",
    "    res_id=res['hits'][0]['_id']\n",
    "    res=res['hits'][0]['_source']\n",
    "    print(res)\n",
    "        \n",
    "    #now update to generating...\n",
    "    \n",
    "    res['status']='generating'\n",
    "    res['start_generating']=int(time()*1000)\n",
    "    es.update(index=index_name, doc_type='doc', id=res_id, body={\"doc\":res})\n",
    "    return (res_id, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def done_generating(id):\n",
    "    res={'status':'generated', 'end_generating':int(time()*1000) }\n",
    "    es.update(index=index_name, doc_type='doc', id=id, body={\"doc\":res})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transfering_job():\n",
    "    my_query={\n",
    "        \"size\": 1,\n",
    "        \"query\":{ \n",
    "            \"term\": {\"status\":\"generated\"} \n",
    "        }\n",
    "    }\n",
    "\n",
    "    res = es.search(index=index_name, body=my_query )\n",
    "    res=res['hits']\n",
    "    if res['total']==0:\n",
    "        print('no transfering jobs at the moment.')\n",
    "        return\n",
    "    res_id=res['hits'][0]['_id']\n",
    "    res=res['hits'][0]['_source']\n",
    "    print(res)\n",
    "        \n",
    "    #now update to transfering...\n",
    "    \n",
    "    res['status']='transfering'\n",
    "    res['start_generating']=int(time()*1000)\n",
    "    es.update(index=index_name, doc_type='doc', id=res_id, body={\"doc\":res})\n",
    "    return (res_id, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def done_transfering(id):\n",
    "    res={'status':'transfered', 'end_transfering':int(time()*1000) }\n",
    "    es.update(index=index_name, doc_type='doc', id=id, body={\"doc\":res})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test all the steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_workload()\n",
    "(id, job) = get_training_job()\n",
    "print(id, job)\n",
    "sleep(5)\n",
    "done_training(id)\n",
    "\n",
    "(id, job) = get_generating_job()\n",
    "print(id, job)\n",
    "sleep(5)\n",
    "done_generating(id)\n",
    "\n",
    "(id, job) = get_transfering_job()\n",
    "print(id, job)\n",
    "sleep(5)\n",
    "done_transfering(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
